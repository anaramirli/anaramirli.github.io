

<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Anar â€¢ Portfolio</title>

  <!-- SEO & Social -->
  <meta name="description" content="Anar Amirli â€” applied AI scientist focusing on interpretable, scalable ML systems." />
  <meta property="og:title" content="Anar Amirli â€” Portfolio" />
  <meta property="og:description" content="Concept-based explainability for vision models, industrial anomaly detection, generative design optimization." />
  <meta property="og:image" content="thumbs/og-cover.png" />
  <meta property="og:type" content="website" />
  <meta name="twitter:card" content="summary_large_image" />
  <link rel="icon" href="/favicon.ico" />

  <!-- Fonts (preconnect for speed) -->
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet" />

  <style>
	  /* =====================
		 THEME TOKENS (light)
		 ===================== */
	  :root {
		/* Softer palette (Option 2: Teal + Warm Neutral) */
		--bg: #fafafa;          /* off-white background to soften contrast */
		--panel: #ffffff;       /* card backgrounds */
		--text: #111111;
		--muted: #555555;
		--accent: #0d9488;      /* teal */
		--accent-900: #0b776d;  /* for hovers */
		--border: #e5e7eb;      /* light gray borders */
		--purple: #a855f7;      /* soft indigo for tiny flourishes */
		--shadow: 0 2px 16px rgba(0,0,0,0.04);
	  }

	  /* Base */
	  html { scroll-behavior: smooth; }
	  @media (prefers-reduced-motion: reduce) { html { scroll-behavior: auto; } }

	  body {
		margin: 0;
		font-family: Inter, system-ui, -apple-system, Segoe UI, Roboto, Ubuntu, Cantarell, Noto Sans, sans-serif;
		background: var(--bg);
		color: var(--text);
		line-height: 1.65;
		text-rendering: optimizeLegibility;
		-webkit-font-smoothing: antialiased;
		-moz-osx-font-smoothing: grayscale;
	  }

	  a { color: var(--accent); text-decoration: none; }
	  a:hover { text-decoration: underline; }
	  a[target="_blank"]::after { content: "â†—"; font-size: .85em; margin-left: .25em; opacity: .6; }
	  a[target="_blank"]:hover::after { opacity: 1; }

	  :focus-visible { outline: 2px solid var(--accent); outline-offset: 2px; border-radius: 4px; }

	  .container { max-width: 1100px; margin: 0 auto; padding: 24px; }

	  header {
		border-bottom: 1px solid var(--border);
		padding: 10px 24px;
		position: sticky; top: 0; z-index: 10;
		background: rgba(250, 250, 250, .85); /* sync with --bg */
		backdrop-filter: blur(8px);
	  }

	  .nav { display: flex; justify-content: space-between; align-items: center; }
	  .nav a { margin-left: 12px; font-weight: 600; padding: 8px 6px; border-radius: 8px; }
	  .nav a:hover { background: #ffffffc2; text-decoration: none; }

	  /* Hidden H1 for SEO/AT */
	  .visually-hidden { position: absolute; left: -9999px; top: auto; width: 1px; height: 1px; overflow: hidden; }

	  h1 { font-size: clamp(28px, 4vw, 40px); margin: 0 0 12px; }
	  h2 {
		font-size: clamp(24px, 3.4vw, 30px);
		margin: 32px 0 12px;
		display: flex; align-items: center; gap: 8px;
		font-weight: 700;
	  }
	  h2::after { content: "â€¢"; color: var(--purple); font-size: 1.4em; line-height: 0; }

	  /* Tighter top spacing for card headers */
	  .cv h2, .training h2, .contact h2 {
		margin-top: 12px;
	  }

	  /* Anchor offset so sticky header won't cover section starts */
	  section { scroll-margin-top: 80px; }

	  /* Panel / Card utility */
	  .card {
		background: var(--panel);
		border: 1px solid var(--border);
		border-radius: 14px;
		box-shadow: var(--shadow);
	  }

	  /* About */
	  .about { display: flex; align-items: center; gap: 20px; padding: 16px; margin-bottom: 24px; }
	  .about img { width: 120px; height: 120px; object-fit: cover; border-radius: 12px; border: 1px solid var(--border); }

	  .links { display: flex; flex-wrap: wrap; gap: 8px; margin-top: 8px; align-items: center; justify-content: space-between; }
	  .links-left { display: flex; flex-wrap: wrap; gap: 8px; }
	  .links a { font-size: 14px; border: 1px solid var(--border); border-radius: 999px; padding: 6px 12px; color: var(--muted); background: #fff; }
	  .links a:hover { border-color: var(--accent); color: var(--accent); text-decoration: none; }

	  .highlight { color: var(--accent); font-weight: 600; }

	  .location { font-size: 14px; color: var(--muted); display: flex; align-items: center; gap: 4px; }

	  /* CV & Training */
	  .cv, .training, .contact { padding: 16px; margin-bottom: 24px; }

	  .cv ul, .training ul { list-style: none; padding: 0; margin: 0; }
	  .cv li, .training li { margin-bottom: 10px; padding-left: 10px; border-left: 3px solid var(--accent); }
	  .cv span, .training span { display: block; font-weight: 600; }

	  /* Projects (list style) */
	  .projects { display: flex; flex-direction: column; gap: 36px; }
	  .project {
		display: grid; grid-template-columns: 1fr 1fr; gap: 24px;
		align-items: start; position: relative;
		border-bottom: 1px solid var(--border);
		padding-bottom: 24px;
		margin-bottom: 36px; /* âœ… Added more breathing room */
	  }
	  .project-media img, .project-media video { width: 100%; border-radius: 10px; border: 1px solid var(--border); object-fit: cover; box-shadow: var(--shadow); }
	  .status { position: absolute; left: -56px; top: 2px; writing-mode: vertical-rl; transform: rotate(180deg); text-transform: uppercase; font-size: 12px; letter-spacing: .08em; color: var(--muted); font-weight: 600; }

	  .p-title { font-size: clamp(22px, 3.2vw, 28px); font-weight: 700; margin: 0 0 6px; }
	  .p-authors { font-weight: 600; margin: 0 0 8px; font-size: 15px; }
	  .p-links { font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace; font-size: 14px; margin-bottom: 12px; opacity: .9; }
	  .p-links a { color: var(--text); }
	  .p-abstract { font-size: 15px; color: var(--muted); }

	  details.summaryless { margin-top: 8px; }
	  details summary { cursor: pointer; user-select: none; transition: opacity .2s ease; }
	  details[open] > summary { opacity: .9; }
	  details p { margin: 8px 0 0; }

	  /* Keep abstracts + summary + read-more text consistent at 15px */
	  .p-abstract, details summary, details p { font-size: 15px; color: var(--muted); }

	  @media (max-width: 900px) {
		.project { grid-template-columns: 1fr; }
		.status {
		  position: static; writing-mode: horizontal-tb; transform: none; display: inline-block;
		  padding: 2px 8px; border: 1px solid var(--border); border-radius: 999px; font-size: 12px; margin-bottom: 8px; background: var(--panel);
		}
	  }

	  /* Contact */
	  .cta { display: flex; flex-wrap: wrap; gap: 10px; margin-top: 10px; }
	  .cta a { padding: 4px 8px; border-radius: 8px; border: 1px solid var(--border); min-height: 26px; display: inline-flex; align-items: center; background: #fff; }
	  .cta .primary { background: var(--accent); color: #fff; border: none; }
	  .cta .primary:hover { background: var(--accent-900); }

	  footer { margin: 40px 0 12px; color: var(--muted); font-size: 14px; text-align: center; }
	</style>
</head>
<body>
  <header>
    <div class="nav">
      <div><strong>Anar Amirli</strong></div>
      <div>
        <a href="#about">About</a>
        <a href="#cv">CV</a>
        <a href="#training">Training</a>
        <a href="#projects">Projects</a>
        <a href="#contact">Contact</a>
      </div>
    </div>
  </header>

  <!-- Hidden H1 for SEO/AT -->
  <h1 class="visually-hidden">Anar Amirli â€” Portfolio</h1>

  <main class="container">
    <!-- About -->
    <section id="about" class="card about">
      <img src="thumbs/me.png" alt="Portrait of Anar Amirli" loading="lazy" width="120" height="120" />
      <div>
        <p>
          Hello, Iâ€™m <span class="highlight">Anar Amirli</span>, an applied AI scientist with experience in building interpretable and scalable machine learning systems. I recently completed my Masterâ€™s in Computer Science at Saarland University, advised by <a href="https://ceo.dfki.de/" class="highlight" target="_blank" rel="noopener">Prof. Antonio KrÃ¼ger</a> and <a href="https://www.dfki.de/~daso02/" class="highlight" target="_blank" rel="noopener">Prof. Daniel Sonntag</a>, where I developed a <span class="highlight">concept-based explainability framework</span> for vision models.
        </p>
        <p>
          Most recently, I worked as a Research Assistant at the <a href="https://dfki.de/web" class="highlight" target="_blank" rel="noopener">German Research Center for AI (DFKI)</a>, contributing to projects ranging from <span class="highlight">AI models for medical imaging</span> to <span class="highlight">real-time risk/anomaly detection systems</span> for manufacturing and cloud-deployed ML workflows. I focus on developing AI systems that are <span class="highlight">practical, trustworthy, and impactful</span> in the real world.
        </p>
        <div class="links">
          <div class="links-left">
            <a href="mailto:anar.amirli@gmail.com">Email</a>
            <!-- <a href="Anar_CV.pdf">CV</a> -->
            <a href="https://github.com/anaramirli" target="_blank" rel="noopener">GitHub</a>
            <a href="https://linkedin.com/in/anar-amirli" target="_blank" rel="noopener">LinkedIn</a>
            <a href="https://scholar.google.com/citations?user=Dx4frMkAAAAJ&hl=en" target="_blank" rel="noopener">Scholar</a>
          </div>
          <div class="location">ðŸŒŽï¸Ž SaarbrÃ¼cken, Germany (sometimes in France)</div>
        </div>
      </div>
    </section>

    <!-- CV -->
    <section id="cv" class="card cv">
      <h2>Short CV</h2>
      <ul>
        <li><span>2025</span> Masterâ€™s Degree, Saarland University, Germany</li>
        <li><span>2022 â€“ 2025</span> Junior Researcher, German Research Center for Artificial Intelligence (DFKI), Germany</li>
        <li><span>2019</span> Bachelorâ€™s Degree, Baku Engineering University, Azerbaijan</li>
      </ul>
    </section>

    <!-- Training -->
    <section id="training" class="card training">
      <h2>Industrial Training &amp; Certifications</h2>
      <ul>
        <li><span>ongoing</span> MLOps Bootcamp: End-to-End ML Project Development (Udemy)</li>
        <li><span>2025</span> Developing Machine Learning Solutions â€“ AWS (Coursera)</li>
        <li><span>2025</span> Generative AI with Large Language Models (Coursera)</li>
      </ul>
    </section>

    <!-- Projects -->
    <section id="projects">
      <h2>Selected Projects</h2>
      <div class="project">
          <div class="status">2025</div>
          <div class="project-media">
            <img src="thumbs/thesis.png" alt="Concept-graph explainability thesis thumbnail" loading="lazy" width="640" height="360">
          </div>
          <div class="project-text">
            <div class="p-title">Beyond Heatmaps: A Visual Concept-Based Explainable Model via Graph Attention Networks</div>
            <div class="p-authors">Anar Amirli</div>
            <div class="p-links">Available upon request or at Campus-Bibliothek</div>
            <p class="p-abstract">
              Explaining how black-box models make decisions is crucial for building trustworthy AI systems, especially in high-stakes domains like healthcare. 
              Traditional attribution methods highlight <em>where</em> a model attends but not <em>what</em> it recognizes. 
              Concept-based methods address this by linking predictions to human-interpretable concepts. 
              This work introduces an ante-hoc explainability framework that combines non-negative matrix factorization (NMF) for unsupervised concept discovery with Graph Attention Networks (GATs) to model relationships between concepts, with a focus on medical imaging.
            </p>
            <details class="summaryless">
              <summary>Read more</summary>
              <p>
                While concept bottleneck models (CBMs) offer promise, they suffer from key limitations: the difficulty of defining clinically meaningful concepts, the high cost of annotations, reliance on heatmaps for localization, and potentially spurious alignment between visual features and textual labels. 
                To avoid these pitfalls and leverage the strengths of vision models, we focus exclusively on visually grounded concepts. 
                However, prior visually grounded methods often produce only global, class-specific explanations, neglect concept interactions, and providing unstable interpretability due to post-hoc nature.
              </p>
              <p>
                Our framework addresses these issues by (a) discovering visual concepts with NMF, and (b) constructing concept graphs that capture interactions through a shallow GAT, balancing expressiveness and interpretability. 
                Although our models do not outperform heavily optimized task-specific CBMs, they demonstrate consistent generalization across medical and standard datasets and, in some cases, surpass baseline CBMs, showcasing a more faithful, visually grounded alternative for explainability.
              </p>
            </details>
          </div>
        </div>

        <div class="project">
          <div class="status">2022</div>
          <div class="project-media">
            <img src="thumbs/anomaly.png" alt="Glass production anomaly detection: sensors and alerts thumbnail" loading="lazy" width="640" height="360">
          </div>
          <div class="project-text">
            <div class="p-title">Real-Time Multivariate Anomaly Detection and Fault Localization for Manufacturing Systems</div>
            <div class="p-authors">Mina Ameli, Anar Amirli, Philipp Aaron Becker, Holger BÃ¤hring, Wolfgang MaaÃŸ</div>
            <div class="p-links">
              <a href="https://link.springer.com/chapter/10.1007/978-3-031-08333-4_41" target="_blank" rel="noopener">Article</a> /
              Code [<a href="https://github.com/spaicer/explanation-generator-module" target="_blank" rel="noopener">1</a>,
              <a href="https://github.com/spaicer/univariate-anomaly-detection-module" target="_blank" rel="noopener">2</a>,
              <a href="https://github.com/spaicer/multivariate-aggregator-module" target="_blank" rel="noopener">3</a>]
            </div>
            <p class="p-abstract">
              Real-time anomaly detection is critical in industrial settings to maintain quality and prevent costly failures. 
              In this work, we study multivariate time series data from glass production and compare unsupervised detection and localization methods. 
              Our two-level approach detects anomalies, categorizes their types, and localizes faulty sensors with the help of explainable AI techniques.
            </p>
            <details class="summaryless">
              <summary>Read more</summary>
              <p>
                Experiments showed that combining statistical pattern recognition with multivariate anomaly detection pipelines significantly improves both accuracy and interpretability. 
                By categorizing anomalies into distinct classes and highlighting faulty sensors, our method provides actionable insights for engineers monitoring production. 
                This pipeline achieved promising results and demonstrates the value of integrating explainability into anomaly detection systems.
              </p>
            </details>
          </div>
        </div>

        <div class="project">
          <div class="status">2022</div>
          <div class="project-media">
            <img src="thumbs/topology.png" alt="Topology optimization generative AI designs thumbnail" loading="lazy" width="640" height="360">
          </div>
          <div class="project-text">
            <div class="p-title">From Multimodal Inputs to Optimized Designs: Generative AI for Topology Optimization in 2D and 3D</div>
            <div class="p-authors">Yelaman Maksum, Anar Amirli, Yulong Ding, Alessandro Romagnoli, Samir Rustamov, Bakytzhan Akhmetov</div>
            <div class="p-links"><a href="https://www.sciencedirect.com/science/article/pii/S2452414X22000231" target="_blank" rel="noopener">Article</a></div>
            <p class="p-abstract">
              This project reframes topology optimization as a multimodal-to-image translation task. 
              We apply generative AI models, including GANs and diffusion models, to translate structured inputs into optimized 2D and 3D designs. 
              The models consistently generate valid, high-quality structures at reduced computational cost.
            </p>
            <details class="summaryless">
              <summary>Read more</summary>
              <p>
                Traditional topology optimization relies on iterative solvers and finite element methods, which are computationally expensive and time-consuming. 
                By leveraging modern generative approaches, we accelerate the design process while preserving structural accuracy. 
                Notably, performance improved at higher iteration levels, underscoring the potential of generative AI to reshape how engineers approach design optimization across multiple modalities.
              </p>
            </details>
          </div>
        </div>
		
		<div class="project">
		  <div class="status">2022</div>
		<!-- <div class="project-media">
			<img src="thumbs/football.png" alt="Football ball location prediction visualization thumbnail" loading="lazy" width="640" height="360">
		  </div> -->
		  <video autoplay muted loop playsinline width="640" height="360" style="border-radius:10px; border:1px solid var(--border); box-shadow:var(--shadow); object-fit:cover;">
			  <source src="thumbs/football.webm" type="video/webm">
			  Your browser does not support the video tag.
		  </video>
		  <div class="project-text">
			<div class="p-title">Prediction of Ball Location in Football Using Optical Tracking Data</div>
			<div class="p-authors">Anar Amirli, Hande Alemdar</div>
			<div class="p-links">
			  <a href="https://doi.org/10.21541/apjess.1060725" target="_blank" rel="noopener">Article</a> /
			  <a href="https://github.com/anaramirli/predict-soccer-ball-location" target="_blank" rel="noopener">Code</a>
			</div>
			<p class="p-abstract">
			  We proposed a machine learningâ€“based method to predict the ball location in football when it is occluded,
			  using only playersâ€™ spatial information from optical tracking data. Trained on 300 matches of the Turkish Super League,
			  our neural network models achieved strong predictive accuracy (RÂ² â‰ˆ 79% for x-axis and 92% for y-axis).
			  This approach can complement vision-based tracking systems and enable more reliable analytics in football.
			</p>
		  </div>
		</div>

    </section>

    <!-- Contact -->
    <section id="contact" class="card contact">
      <h2>Get in touch</h2>
      <p>Iâ€™m currently open to internships and applied research roles in AI, particularly in vision-language models, explainability, healthcare, and risk management. If youâ€™d like to learn more about what Iâ€™m working on, the best way is to get in touch. Iâ€™d be happy to hear from you!</p>
      <div class="cta">
		<a href="mailto:anar.amirli@gmail.com" class="primary">Email me</a>
        <a href="https://github.com/anaramirli" target="_blank" rel="noopener">GitHub</a>
        <a href="https://linkedin.com/in/anar-amirli" target="_blank" rel="noopener">LinkedIn</a>
      </div>
    </section>

    <footer>
      Â© <span id="year"></span> Anar Amirli @ SaarbrÃ¼cken, Germany. All rights reserved.
    </footer>
  </main>

  <script>
    document.getElementById('year').textContent = new Date().getFullYear();
  </script>
</body>
</html>